DIFF√âRENCE ENTRE UN MCP-SERVER ET UNE API REST
Le serveur MCP permet de d√©couvrir dynamiquement des outils par l'hote (et que l'AI va √™tre capable d'utiliser). Dans le cas de l'API,
 il faut connaitre et configurer les routes √† appeler en se basant sur une documentation.
 Concr√®etement si on ajoute de nouveaux outils depuis le HOST du serveur, ceci sera automatiquement decouvert du c√¥t√© de
  l'hote sans avoir √† y rajouter une documentation.
--> Transport Type: STDIO

On peut avoir un server MCP depuis une image-docker, depuis un remote HTTP, ou meme en local (via la commande stdio) etc.

Un server-mcp est une sorte d'interm√©diaire entre mon IA et des sources de donn√©es 

CR√âATION D'UN SERVEUR MCP pour r√©cup√©rer la m√©t√©o via une API (avec Open m√©t√©o):
Le model de copilot est limit√© √† 128 outils, d'o√π la bonne pratique de d√©cocher les server-mcp non utiles pour tel 
ou tel fonctionnalit√©.

Permettre √† l'IA d'√©crire sur Discord via un Serveur MCP connect√© √† un webhook:
-->En entreprise ca peut etre tres utile avec le webhook de Teams pour remonter des alertes.

Cr√©ation d'un Serveur MCP capable de r√©cup√©rer de la documentation en ligne:
-->Creer un serveur MCP qui permet d'avoir acces en temps reel √† la documentation et de la documentation √† jour.
ou meme de la documentation priv√©e qui serait interne √† votre entreprise.√†
  üìö Diff√©rence entre Tools et Resources
  Resources (Ressources)
  Donn√©es statiques ou semi-statiques que l'IA peut consulter
  Pas de param√®tres (ou param√®tres tr√®s simples comme un URI)
  Exemples : documentation, conventions de code, configuration
  L'IA les lit passivement
  Tools (Outils)
  Actions ex√©cutables avec des param√®tres
  Logique dynamique : recherche, calcul, transformation
  Exemples : rechercher dans une API, filtrer des donn√©es, calculer
  L'IA les ex√©cute activement

Cr√©ation d'une base de donn√©es d'exemple pour servir de contexte √† l'IA:
-->une API avec Express qui permet de visualiser tout le contenu d'une BD

Acc√©der aux tools d'un Serveur MCP depuis LM Studio:
D√©velopper une sorte de client-mcp en choisisant un bon model (bien v√©rifier les compatibilit√©s avec l'environnement local(GPU, RAM, etc)) 
dans LM Studio...Cette fois-ci via LM Studio, on utilise des model en local, mais dans des projets futurs comme la finalisation 
de AICodeMentor, on peut utiliser des models en ligne comme celui de Grock ou OpenAI.

 Permettre √† une IA d'allumer la lumi√®re gr√¢ce √† un serveur MCP d√©di√©: Les lumi√®eres de marque: Philips Hue (IOT)


Cr√©ation d'un client MCP en ligne de commandes
-->On va app√©ler deux fois cons√©cutivemnent LM Studio: la 1ere fois (si besoin) pour d√©clencher un outil , la 2e fois pour 
Read [](file:///Users/nelsonjunioryimounoubissi/Downloads/McpServerUdemyNelson-main/mcp-client/client.ts#1-1), lines 1 to 80

**Logique globale MCP Client :**

```
Utilisateur ‚Üí Client MCP ‚Üí LLM (LM Studio) ‚Üí Tools MCP Server ‚Üí R√©ponse
```

1. **Client** se connecte au serveur MCP et r√©cup√®re les tools disponibles
2. **Utilisateur** pose une question
3. **Client** envoie la question + liste des tools au **LLM**
4. **LLM** d√©cide s'il a besoin d'un tool (ex: r√©cup√©rer la m√©t√©o)
5. Si oui ‚Üí **Client** appelle le tool via **MCP Server**
6. **R√©sultat** du tool retourne au **LLM** qui g√©n√®re la r√©ponse finale

---

**LM Studio vs LLM en ligne :**

| **LM Studio** | **Grok/OpenAI** |
|---------------|-----------------|
| ‚úÖ **Local** (ton Mac) | ‚òÅÔ∏è **Cloud** (Internet) |
| ‚úÖ **Gratuit** | üí∞ **Payant** |
| ‚úÖ **Priv√©** (tes donn√©es restent chez toi) | ‚ö†Ô∏è **Donn√©es envoy√©es** en ligne |
| ‚ùå Moins puissant | ‚úÖ Plus puissant |
| ‚ùå Besoin RAM/CPU | ‚úÖ Pas de ressources locales |

Cr√©atiuon d'un client MCP avec interface graphique:
ICI webServer.js est un serveur HTTP Express qui √©coute les requetes venant d'une interface web cette fois ci
Pareillement avec celui avec lignes de commandes, sa logique m√©tier est: 
-->Connexion au serveur MCP via StdioClientTransport
-->R√©cup√©ration des tools disponibles
-->Communication avec LM Studio
-->Gestion des tool_calls et r√©ponses